{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg7x8PdQhTH0"
      },
      "source": [
        "Link to Colab notebook: https://colab.research.google.com/drive/1YT3M4-fIakqLP0ITYTusXDcZ1BzNvwpu?usp=sharing\n",
        "\n",
        "All code was run locally on one team member's device\n",
        "\n",
        "Due to time and GPU usage constraints, code was not run on Colab. For more information on results of the code (i.e. print outputs), visit this link to view the separate Jupyter notebooks used to run the project: https://drive.google.com/drive/folders/1qKlqJc7a75tm3EPjvDzx8BFxgwBB1Wkk?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSTOzP5agtO8"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QitkX968h0-M"
      },
      "source": [
        "## Downloading SONICS dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eoa-9_U9hGUh"
      },
      "source": [
        "Downloaded files are zipped, which are then unzipped and stored locally on a home device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3F0X769hBUe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import snapshot_download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx6sxK9DhCFT"
      },
      "outputs": [],
      "source": [
        "datasets_dir = f'{os.getcwd()}/datasets'\n",
        "test = snapshot_download(\n",
        "    repo_id=\"awsaf49/sonics\",\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=datasets_dir\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWIMDc7qi4pq"
      },
      "source": [
        "## Downloading real music clips"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Jk65mMyi_uJ"
      },
      "source": [
        "The SONICS dataset comes with a real_music.csv file, which contains YouTube links to real music files. The YoutubeDL pipeline is used here to download these files and store them locally as mp3 files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsXD0gz-jS5X"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from yt_dlp import YoutubeDL\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHmc812hi-ts"
      },
      "outputs": [],
      "source": [
        "def download_single_task(args):\n",
        "    \"\"\"\n",
        "    Worker function to download a single YouTube ID to MP3 at given bitrate.\n",
        "    Returns (youtube_id, success: bool, message: str).\n",
        "    \"\"\"\n",
        "    youtube_id, output_dir, bitrate = args\n",
        "    url = f\"https://www.youtube.com/watch?v={youtube_id}\"\n",
        "    outtmpl = os.path.join(output_dir, f\"{youtube_id}.%(ext)s\")\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': str(bitrate),\n",
        "        }],\n",
        "        'noplaylist': True,\n",
        "        'outtmpl': outtmpl,\n",
        "    }\n",
        "    try:\n",
        "        with YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "        mp3_path = os.path.join(output_dir, f\"{youtube_id}.mp3\")\n",
        "        if os.path.isfile(mp3_path):\n",
        "            return youtube_id, True, f\"Downloaded: {mp3_path}\"\n",
        "        else:\n",
        "            return youtube_id, False, f\"Missing file after download\"\n",
        "    except Exception as e:\n",
        "        return youtube_id, False, str(e)\n",
        "\n",
        "\n",
        "def download_and_convert(\n",
        "    csv_path: str,\n",
        "    output_dir: str,\n",
        "    target_count: int = 10000,\n",
        "    bitrate: int = 64,\n",
        "    workers: int = 4\n",
        "):\n",
        "    \"\"\"\n",
        "    Reads a CSV with a 'youtube_id' column, downloads audio as MP3 via yt-dlp\n",
        "    in parallel across multiple threads, until target_count successes.\n",
        "    Uses ThreadPoolExecutor with given number of worker threads.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    df = pd.read_csv(csv_path)\n",
        "    if 'youtube_id' not in df.columns:\n",
        "        raise ValueError(\"CSV must contain a 'youtube_id' column\")\n",
        "\n",
        "    total_rows = len(df)\n",
        "    success_count = 0\n",
        "    submitted = 0\n",
        "\n",
        "    # Prepare list of IDs\n",
        "    ids = [str(y).strip() for y in df['youtube_id'].tolist() if str(y).strip()]\n",
        "    print(f\"Starting parallel download: target={target_count}, workers={workers}, total IDs available={len(ids)}\")\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=workers) as executor:\n",
        "        # Submit jobs up to all IDs, but will stop early when target reached\n",
        "        future_to_id = {}\n",
        "        for youtube_id in ids:\n",
        "            if submitted >= total_rows:\n",
        "                break\n",
        "            future = executor.submit(download_single_task, (youtube_id, output_dir, bitrate))\n",
        "            future_to_id[future] = youtube_id\n",
        "            submitted += 1\n",
        "\n",
        "        for future in as_completed(future_to_id):\n",
        "            youtube_id = future_to_id[future]\n",
        "            success = False\n",
        "            try:\n",
        "                _, success, msg = future.result()\n",
        "            except Exception as e:\n",
        "                msg = str(e)\n",
        "            if success:\n",
        "                success_count += 1\n",
        "            print(f\"[{success_count}/{target_count}] {youtube_id}: {msg}\")\n",
        "            if success_count >= target_count:\n",
        "                # Cancel remaining futures\n",
        "                for fut in future_to_id:\n",
        "                    if not fut.done():\n",
        "                        fut.cancel()\n",
        "                break\n",
        "\n",
        "    print(f\"Finished: {success_count} successful downloads (target was {target_count})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCJtMLkFjmBV"
      },
      "outputs": [],
      "source": [
        "download_and_convert(\n",
        "    csv_path=f\"{os.getcwd()}\\\\datasets\\\\real_songs.csv\",\n",
        "    output_dir=f\"{os.getcwd()}\\\\datasets\\\\real_songs\",\n",
        "    target_count=10000,\n",
        "    workers=12\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qkl0Jekmh5Hj"
      },
      "source": [
        "## Converting mp3 files to mel-spectrograms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljkTM0GSiRg_"
      },
      "source": [
        "The mp3 files are then converted into mel-spectrograms of dimension 256x256 (with 3 channels) with the help of the librosa library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiQpk3HPioor"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import librosa\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRCfpzqJjxw4"
      },
      "outputs": [],
      "source": [
        "def process_melspectrograms(\n",
        "    input_dir: str,\n",
        "    output_dir: str,\n",
        "    sample_rate: int = 22050,\n",
        "    n_mels: int = 256,\n",
        "    hop_length: int = 512,\n",
        "    fmin: int = 0,\n",
        "    fmax: int = None,\n",
        "    top_db: int = 80,\n",
        "    target_frames: int = 256,\n",
        "    num_channels: int = 3,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Convert all .mp3 files in input_dir to normalized Mel-spectrogram\n",
        "    tensors of shape (num_channels, 256, 256) and save them as .pt in output_dir.\n",
        "\n",
        "    - Uses n_mels=256 bins and fixes time dimension to 256 frames.\n",
        "    - Outputs 3-channel if num_channels=3 by duplicating the grayscale mel.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    mp3_paths = glob.glob(os.path.join(input_dir, \"*.mp3\"))\n",
        "\n",
        "    for mp3_path in mp3_paths:\n",
        "        fname = os.path.splitext(os.path.basename(mp3_path))[0]\n",
        "\n",
        "        # 1. Load audio\n",
        "        y, sr = librosa.load(mp3_path, sr=sample_rate)\n",
        "\n",
        "        # 2. Compute Mel-spectrogram\n",
        "        S = librosa.feature.melspectrogram(\n",
        "            y=y, sr=sr,\n",
        "            n_mels=n_mels,\n",
        "            hop_length=hop_length,\n",
        "            fmin=fmin,\n",
        "            fmax=fmax\n",
        "        )\n",
        "\n",
        "        # 3. Convert to dB\n",
        "        S_db = librosa.power_to_db(S, ref=1.0, top_db=top_db)\n",
        "\n",
        "        # 4. Crop or pad time axis to target_frames\n",
        "        _, t = S_db.shape\n",
        "        if t >= target_frames:\n",
        "            S_db = S_db[:, :target_frames]\n",
        "        else:\n",
        "            pad_amt = target_frames - t\n",
        "            S_db = np.pad(\n",
        "                S_db,\n",
        "                pad_width=((0, 0), (0, pad_amt)),\n",
        "                mode=\"constant\",\n",
        "                constant_values=-top_db\n",
        "            )\n",
        "\n",
        "        # 5. Normalize to [0, 1]\n",
        "        S_norm = np.clip((S_db + top_db) / top_db, 0.0, 1.0).astype(np.float32)\n",
        "\n",
        "        # 6. To torch tensor, grayscale\n",
        "        tensor = torch.from_numpy(S_norm).unsqueeze(0)  # (1, 256, 256)\n",
        "\n",
        "        # 7. Expand to num_channels (3 => RGB by replication)\n",
        "        if num_channels == 3:\n",
        "            tensor = tensor.repeat(3, 1, 1)\n",
        "        elif num_channels != 1:\n",
        "            raise ValueError(f\"Unsupported num_channels={num_channels}\")\n",
        "\n",
        "        # 8. Save\n",
        "        out_path = os.path.join(output_dir, f\"{fname}_mel.pt\")\n",
        "        torch.save(tensor, out_path)\n",
        "\n",
        "    print(f\"Processed {len(mp3_paths)} files → {output_dir} (shape: {num_channels},256,256)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4Fvnrbdj1HQ"
      },
      "outputs": [],
      "source": [
        "# Process fake songs to mel-spectograms\n",
        "process_melspectrograms(\n",
        "    input_dir=f\"{os.getcwd()}\\\\datasets\\\\fake_songs\",\n",
        "    output_dir=f\"{os.getcwd()}\\\\datasets\\\\fake_songs_mel\"\n",
        ")\n",
        "\n",
        "# Process real songs to mel-spectograms\n",
        "process_melspectrograms(\n",
        "    input_dir=f\"{os.getcwd()}\\\\datasets\\\\real_songs\",\n",
        "    output_dir=f\"{os.getcwd()}\\\\datasets\\\\real_songs_mel\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZvgZ7E8j_Z2"
      },
      "source": [
        "An example from both real and fake music datasets are plotted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSlPchK3kEDK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a Mel-spectrogram\n",
        "mel_tensor = torch.load(f\"{os.getcwd()}\\\\datasets\\\\fake_songs_mel\\\\fake_00001_suno_0_mel.pt\")\n",
        "mel_np = mel_tensor.numpy()  # shape: (mel_bins, time)\n",
        "\n",
        "# Plot it\n",
        "plt.figure(figsize=(10, 4))\n",
        "if mel_np.ndim == 2:\n",
        "    # single-channel: previous behavior\n",
        "    plt.imshow(mel_np, aspect=\"auto\", origin=\"lower\", cmap=\"magma\")\n",
        "    plt.colorbar(label=\"dB (normalized)\")\n",
        "else:\n",
        "    # multi-channel RGB: permute and drop the colormap\n",
        "    # shape -> (H, W, C)\n",
        "    mel_img = mel_np.transpose(1, 2, 0)\n",
        "    plt.imshow(mel_img, aspect=\"auto\", origin=\"lower\")\n",
        "plt.xlabel(\"Time frames\")\n",
        "plt.ylabel(\"Mel bins\")\n",
        "plt.title(\"Mel-Spectrogram\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfsdqREqkGfO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a Mel-spectrogram\n",
        "mel_tensor = torch.load(f\"{os.getcwd()}\\\\datasets\\\\real_songs_mel\\\\_4-0dnvknOY_mel.pt\")\n",
        "mel_np = mel_tensor.numpy()  # shape: (mel_bins, time)\n",
        "\n",
        "# Plot it\n",
        "plt.figure(figsize=(10, 4))\n",
        "if mel_np.ndim == 2:\n",
        "    # single-channel: previous behavior\n",
        "    plt.imshow(mel_np, aspect=\"auto\", origin=\"lower\", cmap=\"magma\")\n",
        "    plt.colorbar(label=\"dB (normalized)\")\n",
        "else:\n",
        "    # multi-channel RGB: permute and drop the colormap\n",
        "    # shape -> (H, W, C)\n",
        "    mel_img = mel_np.transpose(1, 2, 0)\n",
        "    plt.imshow(mel_img, aspect=\"auto\", origin=\"lower\")\n",
        "plt.xlabel(\"Time frames\")\n",
        "plt.ylabel(\"Mel bins\")\n",
        "plt.title(\"Mel-Spectrogram\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pwjgYwXkNh_"
      },
      "source": [
        "## Creating train/val/test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht5DAr-1kTc1"
      },
      "source": [
        "As a new dataset of 10,000 real and 10,000 fake songs was engineered (due to runtime constraints), we created a 60:20:20 train/val/test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBVFEHvxklZA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSxCKAp_koHP"
      },
      "outputs": [],
      "source": [
        "def create_split_csvs(\n",
        "    real_dir,\n",
        "    fake_dir,\n",
        "    output_dir,\n",
        "    train_ratio: float = 0.6,\n",
        "    val_ratio: float = 0.2,\n",
        "    test_ratio: float = 0.2,\n",
        "    random_state: int = 42\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate train/val/test CSV files listing mel-spectrogram .pt file paths and labels.\n",
        "\n",
        "    Args:\n",
        "        real_dir: Directory containing real mel .pt files (label=0).\n",
        "        fake_dir: Directory containing fake mel .pt files (label=1).\n",
        "        output_dir: Directory to save train.csv, val.csv, and test.csv.\n",
        "    \"\"\"\n",
        "    real_dir = Path(real_dir)\n",
        "    fake_dir = Path(fake_dir)\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Gather file paths using pathlib (produces POSIX paths compatible with torch.load)\n",
        "    real_paths = sorted(real_dir.glob('*.pt'))\n",
        "    fake_paths = sorted(fake_dir.glob('*.pt'))\n",
        "\n",
        "    real_labels = [0] * len(real_paths)\n",
        "    fake_labels = [1] * len(fake_paths)\n",
        "\n",
        "    # Combine lists\n",
        "    all_paths = [p.as_posix() for p in real_paths + fake_paths]\n",
        "    all_labels = real_labels + fake_labels\n",
        "\n",
        "    # First split off test set\n",
        "    train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
        "        all_paths,\n",
        "        all_labels,\n",
        "        test_size=test_ratio,\n",
        "        random_state=random_state,\n",
        "        stratify=all_labels\n",
        "    )\n",
        "\n",
        "    # Then split train and validation\n",
        "    relative_val_size = val_ratio / (train_ratio + val_ratio)\n",
        "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "        train_val_paths,\n",
        "        train_val_labels,\n",
        "        test_size=relative_val_size,\n",
        "        random_state=random_state,\n",
        "        stratify=train_val_labels\n",
        "    )\n",
        "\n",
        "    # Create DataFrames\n",
        "    train_df = pd.DataFrame({'file_path': train_paths, 'label': train_labels})\n",
        "    val_df   = pd.DataFrame({'file_path': val_paths,   'label': val_labels})\n",
        "    test_df  = pd.DataFrame({'file_path': test_paths,  'label': test_labels})\n",
        "\n",
        "    # Save CSVs\n",
        "    train_df.to_csv(output_dir / 'train.csv', index=False)\n",
        "    val_df.to_csv(output_dir / 'val.csv',   index=False)\n",
        "    test_df.to_csv(output_dir / 'test.csv', index=False)\n",
        "\n",
        "    print(f\"Saved splits to {output_dir}:\")\n",
        "    print(f\"  train.csv: {len(train_df)} samples\")\n",
        "    print(f\"  val.csv:   {len(val_df)} samples\")\n",
        "    print(f\"  test.csv:  {len(test_df)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30v7gPsjkotO"
      },
      "outputs": [],
      "source": [
        "base_dir = Path.cwd() / 'datasets'\n",
        "create_split_csvs(\n",
        "    real_dir=base_dir / 'real_songs_mel',\n",
        "    fake_dir=base_dir / 'fake_songs_mel',\n",
        "    output_dir=base_dir\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4GMekF6kswD"
      },
      "source": [
        "#Deep learning boilerplate code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40WWj4PZlaXk"
      },
      "source": [
        "Defining classes and functions essential for the training pipeline later on for both models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1Ojd9ccm19L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVKaB3zwmFAa"
      },
      "source": [
        "## MelCSVDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-ys9IO6lm_I"
      },
      "source": [
        "MelCSVDataset is a class defined for the DataLoader function to take mini batches later on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNvm2buZkxu7"
      },
      "outputs": [],
      "source": [
        "class MelCSVDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Loads mel-spectrogram .pt files and labels from a CSV.\n",
        "    CSV must have 'file_path' and 'label' columns.\n",
        "\n",
        "    Args:\n",
        "      csv_path: path to train.csv or val.csv\n",
        "      img_size:  size to interpolate spectrogram to (HxW)\n",
        "      num_channels: output channels (1 or 3)\n",
        "      unit_variance: if True, (x - mean)/std; else min–max to [0,1]\n",
        "      eps: small constant to avoid div-by-zero\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        csv_path: str,\n",
        "        img_size: int = 256,\n",
        "        num_channels: int = 3,\n",
        "        unit_variance: bool = False,\n",
        "        eps: float = 1e-6\n",
        "    ):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        self.paths = df['file_path'].tolist()\n",
        "        self.labels = df['label'].astype(int).tolist()\n",
        "        self.img_size = img_size\n",
        "        self.num_channels = num_channels\n",
        "        self.unit_variance = unit_variance\n",
        "        self.eps = eps\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # load raw mel-spectrogram tensor, shape (C, H, W)\n",
        "        mel = torch.load(self.paths[idx], map_location='cpu', weights_only=True)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # adapt channels\n",
        "        if mel.size(0) == 1 and self.num_channels == 3:\n",
        "            mel = mel.repeat(3, 1, 1)\n",
        "        elif mel.size(0) > self.num_channels:\n",
        "            mel = mel[:self.num_channels]\n",
        "\n",
        "        # resize to (num_channels, img_size, img_size)\n",
        "        mel = F.interpolate(\n",
        "            mel.unsqueeze(0),\n",
        "            size=(self.img_size, self.img_size),\n",
        "            mode='bilinear',\n",
        "            align_corners=False\n",
        "        ).squeeze(0)\n",
        "\n",
        "        # ==== NORMALIZATION ====\n",
        "        if self.unit_variance:\n",
        "            mean = mel.mean()\n",
        "            std = mel.std()\n",
        "            mel = (mel - mean) / (std + self.eps)\n",
        "        else:\n",
        "            mn = mel.min()\n",
        "            mx = mel.max()\n",
        "            mel = (mel - mn) / (mx - mn + self.eps)\n",
        "        # =======================\n",
        "\n",
        "        return mel, torch.tensor(label, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IvSowXEmJiQ"
      },
      "source": [
        "## train_one_epoch / validate_one_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGJqzVFBmSKT"
      },
      "source": [
        "Boilerplate code for the training and validation of one epoch, with losses and accuracy computed and printed so progress can be monitored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDjkDxAQmZWM"
      },
      "outputs": [],
      "source": [
        "# Training and validation loops\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch_idx, (x, y) in enumerate(tqdm(loader, desc='Train batches')):\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        if batch_idx % 20 == 0:\n",
        "            print(f\"  Batch {batch_idx}/{len(loader)} — loss: {loss.item():.4f}\")\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def validate_one_epoch(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (x, y) in enumerate(tqdm(loader, desc='Val batches')):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item()\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    acc = correct / total\n",
        "    print(f\"Validation Loss: {avg_loss:.4f}, Accuracy: {acc:.4f}\")\n",
        "    return avg_loss, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw-IUj69mdDd"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLqY5PpdnUr1"
      },
      "source": [
        "Model: 'lambda_resnet26rpt_256.c1_in1k'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9ZY06uXmleP"
      },
      "outputs": [],
      "source": [
        "# Main entry point\n",
        "def CNN(\n",
        "    train_csv: str,\n",
        "    val_csv: str,\n",
        "    batch_size: int = 32,\n",
        "    workers: int = 0,\n",
        "    epochs: int = 5,\n",
        "    lr: float = 1e-5,\n",
        "    model_name: str = 'lambda_resnet26rpt_256.c1_in1k'\n",
        "):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # device = torch.device('cpu')\n",
        "\n",
        "    # — Dataset & Dataloaders —\n",
        "    train_loader = DataLoader(\n",
        "        MelCSVDataset(train_csv, unit_variance=True), batch_size=batch_size,\n",
        "        shuffle=True, num_workers=workers, pin_memory=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        MelCSVDataset(val_csv, unit_variance=True), batch_size=batch_size,\n",
        "        shuffle=False, num_workers=workers, pin_memory=True\n",
        "    )\n",
        "\n",
        "    # — Model, optimizer, criterion —\n",
        "    model = timm.create_model(\n",
        "        model_name,\n",
        "        pretrained=True,\n",
        "        num_classes=2,\n",
        "        in_chans=3\n",
        "    ).to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # — Logging setup —\n",
        "    os.makedirs('logs', exist_ok=True)\n",
        "    log_csv = os.path.join('logs', 'losses_lambda.csv')\n",
        "    # If starting fresh, write header; if resuming, append\n",
        "    write_header = not os.path.exists('checkpoints_lambda/resume.pt')\n",
        "    with open(log_csv, 'a') as f:\n",
        "        if write_header:\n",
        "            f.write('epoch,train_loss,val_loss,val_acc\\n')\n",
        "\n",
        "    # — Checkpoint setup —\n",
        "    ckpt_dir        = 'checkpoints_lambda'\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "    resume_path     = os.path.join(ckpt_dir, 'resume.pt')\n",
        "    best_model_path = os.path.join(ckpt_dir, 'best_model.pt')\n",
        "\n",
        "    start_epoch = 1\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # — Resume if possible —\n",
        "    if os.path.exists(resume_path):\n",
        "        ckpt = torch.load(resume_path, map_location=device)\n",
        "        model.load_state_dict(ckpt['model_state'])\n",
        "        optimizer.load_state_dict(ckpt['optim_state'])\n",
        "        start_epoch = ckpt['epoch'] + 1\n",
        "        best_val_loss = ckpt['best_val_loss']\n",
        "        print(f\"Resumed from epoch {ckpt['epoch']} with best_val_loss = {best_val_loss:.4f}\")\n",
        "\n",
        "    # — Storage for curves —\n",
        "    train_losses, val_losses, val_accs = [], [], []\n",
        "\n",
        "    # — Training loop with checkpointing —\n",
        "    for epoch in tqdm(range(start_epoch, epochs + 1), desc='Epochs'):\n",
        "        # ---- train ----\n",
        "        tl = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        # ---- validate ----\n",
        "        vl, va = validate_one_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "        # ---- record logs ----\n",
        "        train_losses.append(tl)\n",
        "        val_losses.append(vl)\n",
        "        val_accs.append(va)\n",
        "        with open(log_csv, 'a') as f:\n",
        "            f.write(f\"{epoch},{tl:.6f},{vl:.6f},{va:.4f}\\n\")\n",
        "        print(f\"Epoch {epoch}/{epochs} - Train: {tl:.4f}, Val Loss: {vl:.4f}, Val Acc: {va:.4f}\")\n",
        "\n",
        "        # ---- save best-model snapshot first (if improved) ----\n",
        "        if vl < best_val_loss:\n",
        "            best_val_loss = vl\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"🎉 New best model saved at epoch {epoch} (val_loss {vl:.4f})\")\n",
        "\n",
        "        # ---- now save the resume checkpoint with the updated best_val_loss ----\n",
        "        torch.save({\n",
        "            'epoch'        : epoch,\n",
        "            'model_state'  : model.state_dict(),\n",
        "            'optim_state'  : optimizer.state_dict(),\n",
        "            'best_val_loss': best_val_loss\n",
        "        }, resume_path)\n",
        "\n",
        "    # — After training, save final plots —\n",
        "    epochs_range = range(1, len(train_losses) + 1)\n",
        "    plt.figure()\n",
        "    plt.plot(epochs_range, train_losses, label='Train Loss')\n",
        "    plt.plot(epochs_range, val_losses,   label='Val Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('logs/loss_curve_lambda.png')\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epochs_range, val_accs, label='Val Acc')\n",
        "    plt.legend()\n",
        "    plt.savefig('logs/acc_curve_lambda.png')\n",
        "\n",
        "    print(\"Training complete. Best validation loss: {:.4f}\".format(best_val_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKQzPKT0m9Pd"
      },
      "outputs": [],
      "source": [
        "# Training for 5 epochs\n",
        "CNN(\n",
        "    train_csv=f\"{os.getcwd()}\\\\datasets\\\\train.csv\",\n",
        "    val_csv=f\"{os.getcwd()}\\\\datasets\\\\val.csv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o8eyoLRnJQV"
      },
      "source": [
        "After training, the finetuned CNN model is ran on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWoW00senE46"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# Obtain testing accuracy\n",
        "test_csv = f\"{os.getcwd()}\\\\datasets\\\\test.csv\"\n",
        "batch_size = 32\n",
        "workers = 0\n",
        "model_name = 'lambda_resnet26rpt_256.c1_in1k'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "ckpt_path = f\"{os.getcwd()}\\\\checkpoints_lambda\\\\best_model.pt\"\n",
        "\n",
        "test_loader = DataLoader(\n",
        "        MelCSVDataset(test_csv, unit_variance=True), batch_size=batch_size,\n",
        "        shuffle=True, num_workers=workers, pin_memory=True\n",
        "    )\n",
        "\n",
        "model = timm.create_model(\n",
        "    model_name,\n",
        "    pretrained=False,      # we’ll load our own weights\n",
        "    num_classes=2,\n",
        "    in_chans=3\n",
        ").to(device)\n",
        "state = torch.load(ckpt_path, map_location=device)\n",
        "model.load_state_dict(state)\n",
        "model.eval()\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "y_proba = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in tqdm(test_loader, desc='Test batches'):\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "        logits = model(x)\n",
        "        probs = F.softmax(logits, dim=1)[:, 1]\n",
        "        preds = logits.argmax(dim=1)\n",
        "\n",
        "        y_true.extend(y.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "        y_proba.extend(probs.cpu().numpy())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "y_proba = np.array(y_proba)\n",
        "\n",
        "# Compute metrics\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)  # Sensitivity\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "auc = roc_auc_score(y_true, y_proba)\n",
        "\n",
        "# Print results\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"AUC-ROC: {auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efd5rEEynQ7T"
      },
      "source": [
        "# Vision Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYGdFT5PneSq"
      },
      "source": [
        "Model: 'swinv2_small_window16_256.ms_in1k'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXJicMTInkgj"
      },
      "outputs": [],
      "source": [
        "# Main entry point\n",
        "def ViT(\n",
        "    train_csv: str,\n",
        "    val_csv: str,\n",
        "    batch_size: int = 20,\n",
        "    workers: int = 0,\n",
        "    epochs: int = 5,\n",
        "    lr: float = 1e-4,       # changed\n",
        "    model_name: str = 'swinv2_small_window16_256.ms_in1k'\n",
        "):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # device = torch.device('cpu')\n",
        "\n",
        "    # — Dataset & Dataloaders —\n",
        "    train_loader = DataLoader(\n",
        "        MelCSVDataset(train_csv, unit_variance=True), batch_size=batch_size,\n",
        "        shuffle=True, num_workers=workers, pin_memory=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        MelCSVDataset(val_csv, unit_variance=True), batch_size=batch_size,\n",
        "        shuffle=False, num_workers=workers, pin_memory=True\n",
        "    )\n",
        "\n",
        "    # — Model, optimizer, criterion —\n",
        "    model = timm.create_model(\n",
        "        model_name,\n",
        "        pretrained=True,\n",
        "        num_classes=2,\n",
        "        in_chans=3\n",
        "    ).to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # — Logging setup —\n",
        "    os.makedirs('logs', exist_ok=True)\n",
        "    log_csv = os.path.join('logs', 'losses_swim.csv')\n",
        "    # If starting fresh, write header; if resuming, append\n",
        "    write_header = not os.path.exists('checkpoints_swim/resume.pt')\n",
        "    with open(log_csv, 'a') as f:\n",
        "        if write_header:\n",
        "            f.write('epoch,train_loss,val_loss,val_acc\\n')\n",
        "\n",
        "    # — Checkpoint setup —\n",
        "    ckpt_dir        = 'checkpoints_swim'\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "    resume_path     = os.path.join(ckpt_dir, 'resume.pt')\n",
        "    best_model_path = os.path.join(ckpt_dir, 'best_model.pt')\n",
        "\n",
        "    start_epoch = 1\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # — Resume if possible —\n",
        "    if os.path.exists(resume_path):\n",
        "        ckpt = torch.load(resume_path, map_location=device)\n",
        "        model.load_state_dict(ckpt['model_state'])\n",
        "        optimizer.load_state_dict(ckpt['optim_state'])\n",
        "        start_epoch = ckpt['epoch'] + 1\n",
        "        best_val_loss = ckpt['best_val_loss']\n",
        "        print(f\"Resumed from epoch {ckpt['epoch']} with best_val_loss = {best_val_loss:.4f}\")\n",
        "\n",
        "    # — Storage for curves —\n",
        "    train_losses, val_losses, val_accs = [], [], []\n",
        "\n",
        "    # — Training loop with checkpointing —\n",
        "    for epoch in tqdm(range(start_epoch, epochs + 1), desc='Epochs'):\n",
        "        # ---- train ----\n",
        "        tl = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        # ---- validate ----\n",
        "        vl, va = validate_one_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "        # ---- record logs ----\n",
        "        train_losses.append(tl)\n",
        "        val_losses.append(vl)\n",
        "        val_accs.append(va)\n",
        "        with open(log_csv, 'a') as f:\n",
        "            f.write(f\"{epoch},{tl:.6f},{vl:.6f},{va:.4f}\\n\")\n",
        "        print(f\"Epoch {epoch}/{epochs} - Train: {tl:.4f}, Val Loss: {vl:.4f}, Val Acc: {va:.4f}\")\n",
        "\n",
        "        # ---- save best-model snapshot first (if improved) ----\n",
        "        if vl < best_val_loss:\n",
        "            best_val_loss = vl\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"🎉 New best model saved at epoch {epoch} (val_loss {vl:.4f})\")\n",
        "\n",
        "        # ---- now save the resume checkpoint with the updated best_val_loss ----\n",
        "        torch.save({\n",
        "            'epoch'        : epoch,\n",
        "            'model_state'  : model.state_dict(),\n",
        "            'optim_state'  : optimizer.state_dict(),\n",
        "            'best_val_loss': best_val_loss\n",
        "        }, resume_path)\n",
        "\n",
        "    # — After training, save final plots —\n",
        "    epochs_range = range(1, len(train_losses) + 1)\n",
        "    plt.figure()\n",
        "    plt.plot(epochs_range, train_losses, label='Train Loss')\n",
        "    plt.plot(epochs_range, val_losses,   label='Val Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('logs/loss_curve_swim.png')\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epochs_range, val_accs, label='Val Acc')\n",
        "    plt.legend()\n",
        "    plt.savefig('logs/acc_curve_swim.png')\n",
        "\n",
        "    print(\"Training complete. Best validation loss: {:.4f}\".format(best_val_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQbhheGQnoIn"
      },
      "outputs": [],
      "source": [
        "# Training for 5 epochs\n",
        "ViT(\n",
        "    train_csv=f\"{os.getcwd()}\\\\datasets\\\\train.csv\",\n",
        "    val_csv=f\"{os.getcwd()}\\\\datasets\\\\val.csv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YV6TTG2n2TF"
      },
      "source": [
        "After training, the finetuned ViT model is ran on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJwtdI66n3qC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# Obtain testing accuracy\n",
        "test_csv = f\"{os.getcwd()}\\\\datasets\\\\test.csv\"\n",
        "batch_size = 32\n",
        "workers = 0\n",
        "model_name = 'swinv2_small_window16_256.ms_in1k'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "ckpt_path = f\"{os.getcwd()}\\\\checkpoints_swim\\\\best_model.pt\"\n",
        "\n",
        "test_loader = DataLoader(\n",
        "        MelCSVDataset(test_csv, unit_variance=True), batch_size=batch_size,\n",
        "        shuffle=True, num_workers=workers, pin_memory=True\n",
        "    )\n",
        "\n",
        "model = timm.create_model(\n",
        "    model_name,\n",
        "    pretrained=False,      # we’ll load our own weights\n",
        "    num_classes=2,\n",
        "    in_chans=3\n",
        ").to(device)\n",
        "state = torch.load(ckpt_path, map_location=device)\n",
        "model.load_state_dict(state)\n",
        "model.eval()\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "y_proba = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in tqdm(test_loader, desc='Test batches'):\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "        logits = model(x)\n",
        "        probs = F.softmax(logits, dim=1)[:, 1]\n",
        "        preds = logits.argmax(dim=1)\n",
        "\n",
        "        y_true.extend(y.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "        y_proba.extend(probs.cpu().numpy())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "y_proba = np.array(y_proba)\n",
        "\n",
        "# Compute metrics\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)  # Sensitivity\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "auc = roc_auc_score(y_true, y_proba)\n",
        "\n",
        "# Print results\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"AUC-ROC: {auc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
